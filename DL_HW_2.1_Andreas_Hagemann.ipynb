{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python CODE\n",
    "import numpy as np\n",
    "# DO NOT FORGET TO SPECIFY THE SAME SEED\n",
    "np.random.seed (12345)\n",
    "def initialize ( input_dim, hidden_dim , output_dim , batchsize):\n",
    "    W1 = np.random.randn( hidden_dim , input_dim ) * 0.01\n",
    "    b1 = np.zeros(( hidden_dim , ) )\n",
    "    W2 = np.random.randn ( hidden_dim , hidden_dim ) * 0.01\n",
    "    b2 = np.zeros(( hidden_dim , ) )\n",
    "    W3 = np.random.randn ( output_dim , hidden_dim ) * 0.01\n",
    "    b3 = np.zeros(( output_dim , ) )\n",
    "    # list of all network parameters\n",
    "    parameters = [W1, b1 , W2, b2 , W3, b3 ]\n",
    "    # minibatch of input instances\n",
    "    x = np.random.rand( input_dim , batchsize )\n",
    "    # ground truths\n",
    "    y = np.random.randn( output_dim , batchsize )\n",
    "    return parameters , x , y\n",
    "# initialize parameters, inputs and t a r g e t s\n",
    "parameters , x , y = initialize (3 , 4 , 2 , 5)\n",
    "# Functions:\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "def sigmoidDeriv(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self):\n",
    "        self.W1 = []\n",
    "        self.b1 = []\n",
    "        self.W2 = []\n",
    "        self.b2 = []\n",
    "        self.W3 = []\n",
    "        self.b3 = []\n",
    "        self.layer1BefAct = []\n",
    "        self.layer2BefAct = []\n",
    "        self.layer3BefAct = []\n",
    "        self.layer1 = []\n",
    "        self.layer2 = []\n",
    "        self.layer3 = []\n",
    "        \n",
    "        L3OutputGrad = []\n",
    "        L2OutputGrad = []\n",
    "        L2WeightedGrad = []\n",
    "        L1OutputGrad = []\n",
    "        L1WeightedGrad = []\n",
    "        \n",
    "    def setParameters(self, param):\n",
    "        self.W1 = param[0]\n",
    "        self.b1 = param[1]\n",
    "        self.W2 = param[2]\n",
    "        self.b2 = param[3]\n",
    "        self.W3 = param[4]\n",
    "        self.b3 = param[5]\n",
    "    def loss(self, pred, y):\n",
    "        #batch size\n",
    "        M = y.shape[1]\n",
    "        return (1. / M) * np.sum( np.sum(.5 * (pred - y)**2, axis = 0))\n",
    "    def dloss(self, pred,y):\n",
    "        #batch size\n",
    "        M = y.shape[1]\n",
    "        return(pred - y) / M\n",
    "    def layerExec(self, input, weight, bias, act):\n",
    "        output = np.dot(weight, input) + bias[:,None]\n",
    "        #run sigmoid when needed\n",
    "        if act:\n",
    "            outputAct = sigmoid(output)\n",
    "        else:\n",
    "            outputAct = output\n",
    "        return output, outputAct\n",
    "    def forwardPass(self, input, target):\n",
    "        self.layer1BefAct, self.layer1 = self.layerExec(input, self.W1, self.b1, True)\n",
    "        self.layer2BefAct, self.layer2 = self.layerExec(self.layer1, self.W2, self.b2, True)\n",
    "        self.layer3BefAct, self.layer3 = self.layerExec(self.layer2, self.W3, self.b3, False)\n",
    "        return self.loss(self.layer3, target)\n",
    "    def backwardPass(self, target):\n",
    "        self.L3OutputGrad = self.dloss(self.layer3, target)\n",
    "        self.L2OutputGrad = np.dot(self.W3.T, self.L3OutputGrad)\n",
    "        self.L2WeightedGrad = self.L2OutputGrad * sigmoidDeriv(self.layer2BefAct)\n",
    "        self.L1OutputGrad = np.dot(self.W2.T, self.L2WeightedGrad)\n",
    "        self.L1WeightedGrad = self.L1OutputGrad * sigmoidDeriv(self.layer1BefAct)\n",
    "        #print(\"L3OutputGrad:\", self.L3OutputGrad)\n",
    "        #print(\"L2OutputGrad:\", self.L2OutputGrad)\n",
    "        #print(\"L2WeightedGrad:\", self.L2WeightedGrad.T)\n",
    "        #print(\"L1OutputGrad:\", self.L1OutputGrad)\n",
    "        #print(\"L1WeightedGrad:\", self.L1WeightedGrad)\n",
    "    def findGradient(self, input, printResults):\n",
    "        w3_gradient = np.dot(self.L3OutputGrad, self.layer2.T)\n",
    "        b3_gradient = np.sum(self.L3OutputGrad, axis = 1)\n",
    "        w2_gradient = np.dot(self.L2WeightedGrad, self.layer1.T)\n",
    "        b2_gradient = np.sum(self.L2WeightedGrad, axis = 1)\n",
    "        w1_gradient = np.dot(self.L1WeightedGrad, input.T)\n",
    "        b1_gradient = np.sum(self.L1WeightedGrad, axis = 1)\n",
    "        if printResults:\n",
    "            print(\"w3_gradient:\", w3_gradient, \"\\n\")\n",
    "            print(\"b3_gradient:\", b3_gradient, \"\\n\")\n",
    "            print(\"w2_gradient:\", w2_gradient, \"\\n\")\n",
    "            print(\"b2_gradient:\", b2_gradient, \"\\n\")\n",
    "            print(\"w1_gradient:\", w1_gradient, \"\\n\")\n",
    "            print(\"b1_gradient:\", b1_gradient, \"\\n\")\n",
    "        gradients = [w1_gradient, b1_gradient, \n",
    "                     w2_gradient, b2_gradient, \n",
    "                     w3_gradient, b3_gradient]\n",
    "        return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Loss of the forward Pass: 1.0595073989866606 \n",
      "\n",
      "Question 3: Show gradients of loss function for each parameter separately\n",
      "w3_gradient: [[-0.29601562 -0.29315414 -0.29558964 -0.29427093]\n",
      " [-0.00063616 -0.00062495 -0.00062947 -0.00063094]] \n",
      "\n",
      "b3_gradient: [-0.58798803 -0.00125797] \n",
      "\n",
      "w2_gradient: [[ 3.99898284e-06  4.14561394e-06  3.09285858e-06  1.00056924e-05]\n",
      " [-9.83803475e-04 -9.89356662e-04 -9.86819589e-04 -9.82852021e-04]\n",
      " [ 5.26033041e-04  5.29099114e-04  5.26928985e-04  5.30215253e-04]\n",
      " [ 6.09661103e-04  6.13133340e-04  6.11301153e-04  6.10570429e-04]] \n",
      "\n",
      "b2_gradient: [ 6.07123945e-06 -1.96949231e-03  1.05156448e-03  1.22000815e-03] \n",
      "\n",
      "w1_gradient: [[-3.55164801e-07  4.19035853e-07  3.52847230e-06]\n",
      " [ 2.02412923e-06  1.85604158e-06  1.01560709e-06]\n",
      " [ 1.12728984e-05  8.49377219e-06 -3.51794858e-06]\n",
      " [ 6.96166795e-07  6.27452005e-07  2.95038713e-07]] \n",
      "\n",
      "b1_gradient: [6.68064134e-06 3.46671844e-06 1.26685662e-06 1.08561520e-06] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "myNN = NN()\n",
    "myNN.setParameters(parameters)\n",
    "loss = myNN.forwardPass(x,y)\n",
    "print(\"Question 1: Loss of the forward Pass: {}\".format(loss), \"\\n\")\n",
    "myNN.backwardPass(y)\n",
    "print(\"Question 3: Show gradients of loss function for each parameter separately\")\n",
    "gradients = myNN.findGradient(x, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimize NN using Backpropagation:\n",
      "Loss Start: 1.0595073989866606 \n",
      "\n",
      "Loss End: 3.1989944074154646e-09 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimize NN using Backpropagation:\")\n",
    "stepsize = 0.1\n",
    "epochs = 100000\n",
    "print(\"Loss Start: {}\".format(loss), \"\\n\")\n",
    "for i in range(epochs):\n",
    "    j = 0\n",
    "    #print(parameters,\"\\n\")\n",
    "    for n in parameters:\n",
    "        parameters[j] = parameters[j] - (gradients[j] * stepsize)\n",
    "        #print(parameters[j])\n",
    "        j = j + 1\n",
    "    #print(parameters,\"\\n\")\n",
    "    #print(gradients,\"\\n\")\n",
    "    myNN.setParameters(parameters)\n",
    "    #print(myNN.W1)\n",
    "    loss = myNN.forwardPass(x,y)\n",
    "    #print(\"Iteration: {}\".format(1), \"Loss: {}\".format(loss), \"\\n\")\n",
    "    myNN.backwardPass(y)\n",
    "    gradients = myNN.findGradient(x, False)\n",
    "    i=+1\n",
    "print(\"Loss End: {}\".format(loss), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-3.49288549,  1.09913006, -2.50246173],\n",
       "        [-2.5763079 , -1.97075992,  0.66218477],\n",
       "        [-8.13738639, -0.83435172,  3.07104694],\n",
       "        [-1.89310082, -0.22804272, -2.55404911]]),\n",
       " array([0.99180998, 1.49733687, 1.96028822, 0.07172028]),\n",
       " array([[-1.47091433, -0.21902798,  2.44689452, -0.69588546],\n",
       "        [-2.64648835, -1.6000124 ,  4.61908868, -1.63929583],\n",
       "        [-2.36986603, -1.12458137,  4.17080493, -1.39581991],\n",
       "        [ 1.06935427,  3.10964707, -0.3220495 ,  0.67759025]]),\n",
       " array([-0.38104509,  0.32015126,  0.16711511, -0.92562583]),\n",
       " array([[-0.05401687, -1.38844162, -0.93789822,  3.28331664],\n",
       "        [-2.10544546, -4.51555498, -3.97217755,  2.74506886]]),\n",
       " array([-0.21452285,  3.22139556])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
